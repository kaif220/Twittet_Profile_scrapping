{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Declaring constants\n",
    "USER_EMAIL = \"deathstorm226@gmail.com\"\n",
    "USERNAME = \"@deathstorm226\"\n",
    "USER_PASSWORD = \"Mohd@78600\"\n",
    "\n",
    "# Loading the profile links from the CSV File\n",
    "links = []\n",
    "with open('twitter_links.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        links.append(row[0])\n",
    "print(f\"Total number of links: {len(links)}\")\n",
    "\n",
    "# Initializing the Web Driver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://twitter.com/i/flow/login\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Login process\n",
    "input_field = driver.find_element(By.XPATH, \"//input\")\n",
    "input_field.send_keys(USER_EMAIL)\n",
    "input_field.send_keys(Keys.ENTER)\n",
    "time.sleep(10)\n",
    "\n",
    "try:\n",
    "    username_field = driver.find_element(By.XPATH, \"//input[@data-testid='ocfEnterTextTextInput']\")\n",
    "    username_field.send_keys(USERNAME)\n",
    "    username_field.send_keys(Keys.ENTER)\n",
    "    time.sleep(5)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pwd_field = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@name='password']\"))\n",
    ")\n",
    "pwd_field.send_keys(USER_PASSWORD)\n",
    "pwd_field.send_keys(Keys.ENTER)\n",
    "time.sleep(10)\n",
    "\n",
    "dict_list = []\n",
    "\n",
    "# Looping through each link\n",
    "for i, link in enumerate(links):\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        username_div = driver.find_element(By.XPATH, \"//*[contains(@data-testid, 'UserName')]\")\n",
    "    except:\n",
    "        print(f\"Invalid Profile Link. Skipping link: {i+1}\")\n",
    "        continue\n",
    "    username_span = username_div.find_element(By.XPATH, \".//span\")\n",
    "    username = username_span.text\n",
    "\n",
    "    # Fetching bio if exists\n",
    "    try:\n",
    "        bio_div = driver.find_element(By.XPATH, \"//div[@data-testid='UserDescription']\")\n",
    "        bio_span = bio_div.find_element(By.XPATH, \".//span\")\n",
    "        bio = bio_span.text\n",
    "    except:\n",
    "        bio = None\n",
    "\n",
    "    # Fetching website if exists\n",
    "    try:\n",
    "        website_anchor = driver.find_element(By.XPATH, \"//a[@data-testid='UserUrl']\")\n",
    "        website = website_anchor.get_attribute(\"href\")\n",
    "    except:\n",
    "        website = None\n",
    "\n",
    "    # Fetching location if exists\n",
    "    try:\n",
    "        location_span = driver.find_element(By.XPATH, \"//span[@data-testid='UserLocation']\")\n",
    "        location = location_span.text\n",
    "    except:\n",
    "        location = None\n",
    "\n",
    "    # Function to extract numbers with 'K', 'M', or 'B'\n",
    "    def extract_number(text):\n",
    "        match = re.search(r\"([\\d,.]+[KM]?)\", text)  # Extracts numbers with optional 'K' or 'M'\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "    # Fetching following count\n",
    "    try:\n",
    "        following_anchor = driver.find_elements(By.XPATH, \"//a[contains(@href, 'following')]\")[0]\n",
    "        following = extract_number(following_anchor.text)  # Extracting only numbers with suffix\n",
    "    except:\n",
    "        following = None\n",
    "\n",
    "    # Fetching followers count\n",
    "    try:\n",
    "        follower_anchor = driver.find_elements(By.XPATH, \"//a[contains(@href, 'followers')]\")[0]\n",
    "        follower = extract_number(follower_anchor.text)  # Extracting only numbers with suffix\n",
    "    except:\n",
    "        follower = None\n",
    "\n",
    "    # Appending profile details to the list\n",
    "    profile_dict = {\n",
    "        \"Username\": username,\n",
    "        \"Bio\": bio,\n",
    "        \"Location\": location,\n",
    "        \"Following\": following,\n",
    "        \"Follower\": follower,\n",
    "        \"Website\": website\n",
    "    }\n",
    "    dict_list.append(profile_dict)\n",
    "    print(f\"Scraped link: {i+1}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_filename = \"profile.csv\"\n",
    "\n",
    "# Dumping the list of dictionaries to CSV file\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=dict_list[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dict_list)\n",
    "\n",
    "print(f\"Scraped data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code using selenium which automatically put it means scraping data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
